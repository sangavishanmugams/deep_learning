# Advanced Time Series Forecasting with Neural ODEs and Uncertainty Quantification

A production-grade implementation of Neural Ordinary Differential Equations (Neural ODEs) for time series forecasting with integrated uncertainty quantification. This project demonstrates how continuous-time models outperform discrete-time approaches on non-linear, complex temporal data.

## ğŸ“Š Overview

This project implements and compares:
- **Baseline Model**: LSTM neural network (discrete-time)
- **Advanced Model**: Neural ODE with continuous-time dynamics (via `torchdiffeq`)
- **Uncertainty Quantification**: Monte Carlo Dropout for epistemic uncertainty estimation
- **Dataset**: Synthetic non-linear time series with multiple periodicities, trend changes, and stochastic noise

### Key Results

| Model | RMSE | MAE | Improvement |
|-------|------|-----|-------------|
| **LSTM Baseline** | 0.4223 | 0.3414 | â€” |
| **Neural ODE** | 0.3922 | 0.3105 | **7.12% RMSE â†“, 9.05% MAE â†“** |

**Uncertainty Coverage**: 60.67% (MC Dropout with 50 samples, z=1.96)

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip or conda

### Installation

```bash
# Clone repository
git clone https://github.com/sangavishanmugams/deep_learning.git
cd Project

# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate
# Activate (macOS/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Run the Full Pipeline

```bash
# 1. Generate synthetic dataset
python scripts/generate_synthetic.py --n 2000 --out data/synthetic.csv

# 2. Inspect and visualize data
python scripts/inspect_data.py --in data/synthetic.csv --out figures

# 3. Train baseline LSTM
python scripts/baseline_lstm.py --in data/synthetic.csv --seq_len 50 --epochs 50

# 4. Train Neural ODE model (set PYTHONPATH first)
export PYTHONPATH=.  # or on Windows: set PYTHONPATH=.
python scripts/train_neural_ode.py --in data/synthetic.csv --seq_len 50 --epochs 10

# 5. Run MC Dropout inference for uncertainty
python scripts/mc_dropout_inference.py --model models/neural_ode_forecaster.pt --in data/synthetic.csv --mc_samples 100

# 6. Generate final comparison report
python scripts/evaluate_and_compare.py --lstm_model models/lstm_baseline.pt --ode_model models/neural_ode_forecaster.pt --in data/synthetic.csv
```

All outputs are saved to `results/` (metrics) and `figures/` (plots).

## ğŸ“ Project Structure

```
Project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ synthetic.csv                 # Generated time series (2000 points)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ neural_ode.py                 # Neural ODE components (encoder, ODE, decoder)
â”‚   â”œâ”€â”€ lstm_baseline.pt              # Trained LSTM weights
â”‚   â””â”€â”€ neural_ode_forecaster.pt      # Trained Neural ODE weights
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_synthetic.py         # Dataset generation
â”‚   â”œâ”€â”€ inspect_data.py               # EDA and diagnostics
â”‚   â”œâ”€â”€ baseline_lstm.py              # LSTM training
â”‚   â”œâ”€â”€ train_neural_ode.py           # Neural ODE training
â”‚   â”œâ”€â”€ mc_dropout_inference.py       # Uncertainty quantification
â”‚   â””â”€â”€ evaluate_and_compare.py       # Baseline vs Neural ODE comparison
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ series.png                    # Raw time series plot
â”‚   â”œâ”€â”€ baseline_forecast.png         # LSTM predictions
â”‚   â”œâ”€â”€ neural_ode_forecast.png       # Neural ODE predictions
â”‚   â”œâ”€â”€ mc_dropout_uncertainty.png    # Uncertainty bands
â”‚   â”œâ”€â”€ baseline_vs_neuralode.png     # Side-by-side comparison
â”‚   â””â”€â”€ error_comparison.png          # Error distributions
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ baseline_metrics.txt          # LSTM RMSE/MAE
â”‚   â”œâ”€â”€ neural_ode_metrics.txt        # Neural ODE RMSE/MAE
â”‚   â”œâ”€â”€ mc_dropout_metrics.txt        # Uncertainty statistics
â”‚   â””â”€â”€ comparison_metrics.txt        # Detailed comparison
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ README.md                         # This file
â””â”€â”€ REPORT.md                         # Full technical report
```

## ğŸ§  What are Neural ODEs?

Neural ODEs model time series by learning a continuous-time dynamics function rather than discrete transitions:

- **Traditional RNNs/LSTMs**: Learn step-by-step mappings (h_{t} â†’ h_{t+1})
- **Neural ODEs**: Learn the instantaneous rate of change (dh/dt = f(h, t))

This enables:
- âœ… **Smooth trajectories** â€” naturally interpolate between observations
- âœ… **Memory efficiency** â€” constant memory via adjoint method (vs. linear in sequence length)
- âœ… **Irregular sampling** â€” can forecast at any time, not just fixed intervals
- âœ… **Principled dynamics** â€” learn the underlying system rules, not just patterns

## ğŸ“ˆ Key Features

### 1. Synthetic Dataset
- **Non-linear trend** + logistic saturation
- **Multi-scale seasonality** (periods 50 & 200)
- **Time-varying amplitude** (heteroskedasticity)
- **Occasional shocks** (regime changes)

### 2. Baseline LSTM Model
- 1 LSTM layer (64 hidden units) + linear readout
- Trained with Adam optimizer on 1-step-ahead loss
- Quick baseline for comparison

### 3. Neural ODE Model
- **Encoder**: window â†’ latent state (16-dim)
- **ODE Block**: continuous dynamics via Runge-Kutta 4
- **Decoder**: latent state â†’ scalar prediction
- Includes dropout for MC Dropout uncertainty

### 4. Uncertainty Quantification
- **MC Dropout**: run forward pass 50-100 times with dropout active
- **Prediction Intervals**: [mean Â± zÂ·std] with z=1.96 (~95% CI)
- **Coverage Analysis**: empirical % of true values inside intervals

## ğŸ”¬ Technical Details

### Models

- **Neural ODE** uses `torchdiffeq` to numerically solve dh/dt = f(h, t)
- **ODE Solver**: Runge-Kutta 4 (fixed-step, deterministic)
- **Backprop**: Adjoint method for memory efficiency
- **Framework**: PyTorch

### Metrics

- **RMSE** (Root Mean Squared Error): emphasizes larger errors
- **MAE** (Mean Absolute Error): robust to outliers
- **Coverage**: fraction of true values inside prediction intervals

### Dataset Stats

- **Length**: 2000 time steps
- **Train/Val/Test**: 70% / 15% / 15%
- **Window size**: 50 (past observations used for prediction)
- **Target**: one-step-ahead forecast

## ğŸ“Š Results & Interpretation

### Accuracy Comparison
Neural ODE outperforms LSTM by ~7â€“9% on both metrics, validating the continuous-time hypothesis for this smooth, non-linear system.

### Uncertainty (MC Dropout)
- **Coverage**: 60.67% with z=1.96 (conservative; improve by increasing MC samples or dropout rate)
- **Epistemic Uncertainty**: ranges 0.084â€“0.268 across the series

## ğŸ“ Educational Value

This project is suitable for:
- Learning **Neural ODE theory and implementation**
- Understanding **continuous-time vs discrete-time modeling**
- Exploring **uncertainty quantification** in deep learning
- Practicing **production-grade ML code organization**

## ğŸ“š References

- Chen, R. T. Q., et al. (2018). "Neural Ordinary Differential Equations." NeurIPS. ([arXiv](https://arxiv.org/abs/1806.07522))
- Dupont, E., et al. (2019). "Augmented Neural ODEs." NeurIPS.
- Gal & Ghahramani (2016). "Dropout as a Bayesian Approximation." ICML.

## ğŸ›  Troubleshooting

### Import Error: "No module named 'models'"
Set `PYTHONPATH` before running scripts:
```bash
export PYTHONPATH=.
python scripts/train_neural_ode.py ...
```

### GPU Support
To use GPU (optional):
```bash
# Install CUDA-enabled PyTorch
pip install torch torchcuda
```

The code automatically detects and uses GPU if available.

### Slow Training
- Neural ODE forward/backward passes are slower than LSTM due to ODE solving
- Use smaller batch sizes or fewer epochs for quick experiments
- GPU strongly recommended for longer runs

## ğŸ“„ Full Report

See [REPORT.md](REPORT.md) for detailed technical documentation covering:
- Dataset design & justification
- Model architectures & design choices
- Training procedures & hyperparameters
- Results & error analysis
- Uncertainty quantification methodology
- Advantages & disadvantages of Neural ODEs
- Future work recommendations

## ğŸ“ License

This project is provided as-is for educational and research purposes.

## ğŸ‘¤ Author

**Sangavi Shanmugam** â€” Neural ODE time series forecasting project

---

**Last Updated**: February 4, 2026
